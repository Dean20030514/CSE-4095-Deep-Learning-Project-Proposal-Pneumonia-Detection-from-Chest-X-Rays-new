"""
ä½¿ç”¨Optunaè¿›è¡Œæ™ºèƒ½è¶…å‚æ•°æœç´¢

Optunaæ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–è¶…å‚æ•°ä¼˜åŒ–æ¡†æ¶ï¼Œä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç®—æ³•
å¯ä»¥æ›´æ™ºèƒ½åœ°æ¢ç´¢å‚æ•°ç©ºé—´ï¼Œæ¯”éšæœºæœç´¢æˆ–ç½‘æ ¼æœç´¢æ›´é«˜æ•ˆ

å®‰è£…ï¼špip install optuna

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/optuna_hyperparameter_search.py --n_trials 20 --target pneumonia_recall

ä¼˜åŠ¿ï¼š
- æ™ºèƒ½é‡‡æ ·ï¼šåŸºäºè¿‡å»çš„è¯•éªŒç»“æœé€‰æ‹©ä¸‹ä¸€ä¸ªå‚æ•°ç»„åˆ
- å‰ªææœºåˆ¶ï¼šæå‰ç»ˆæ­¢è¡¨ç°ä¸ä½³çš„è®­ç»ƒ
- å¯è§†åŒ–ï¼šå†…ç½®ä¼˜åŒ–è¿‡ç¨‹å¯è§†åŒ–
- åˆ†å¸ƒå¼ï¼šæ”¯æŒå¹¶è¡Œæœç´¢

ä½œè€…ï¼šCSE-4095 Deep Learning Team
"""

import argparse
import yaml
import subprocess
import pandas as pd
from pathlib import Path
from typing import Dict
import optuna
from optuna.trial import TrialState
from datetime import datetime
import json


class OptunaTrainer:
    """ä½¿ç”¨Optunaè¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–çš„è®­ç»ƒå™¨"""
    
    def __init__(self, base_config_path: str, target_metric: str = 'macro_recall',
                 study_name: str = None, storage_path: str = None):
        """
        Args:
            base_config_path: åŸºç¡€é…ç½®æ–‡ä»¶
            target_metric: ä¼˜åŒ–ç›®æ ‡ (macro_recall, pneumonia_recallç­‰)
            study_name: Optuna studyåç§°
            storage_path: æ•°æ®åº“å­˜å‚¨è·¯å¾„ï¼ˆç”¨äºæŒä¹…åŒ–å’Œåˆ†å¸ƒå¼ï¼‰
        """
        self.base_config_path = Path(base_config_path)
        self.target_metric = target_metric
        
        # åŠ è½½åŸºç¡€é…ç½®
        with open(self.base_config_path, 'r', encoding='utf-8') as f:
            self.base_config = yaml.safe_load(f)
        
        # Optunaé…ç½®
        self.study_name = study_name or f"pneumonia_{target_metric}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.storage_path = storage_path
        
        # è¾“å‡ºç›®å½•
        self.output_dir = Path('runs/optuna_optimization') / self.study_name
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"[OptunaTrainer] åˆå§‹åŒ–å®Œæˆ")
        print(f"  - Study: {self.study_name}")
        print(f"  - ç›®æ ‡æŒ‡æ ‡: {target_metric}")
        print(f"  - è¾“å‡º: {self.output_dir}")
    
    def objective(self, trial: optuna.Trial) -> float:
        """
        Optunaçš„ç›®æ ‡å‡½æ•°
        
        Args:
            trial: Optunaè¯•éªŒå¯¹è±¡
        
        Returns:
            ç›®æ ‡æŒ‡æ ‡çš„å€¼ï¼ˆOptunaä¼šæœ€å¤§åŒ–è¿™ä¸ªå€¼ï¼‰
        """
        # 1. å»ºè®®è¶…å‚æ•°
        config = self.base_config.copy()
        
        # å­¦ä¹ ç‡ï¼ˆå¯¹æ•°å°ºåº¦ï¼‰
        config['lr'] = trial.suggest_float('lr', 1e-4, 1e-2, log=True)
        
        # Batch sizeï¼ˆç¦»æ•£å€¼ï¼‰
        config['batch_size'] = trial.suggest_categorical('batch_size', [8, 16, 32])
        
        # æ¨¡å‹æ¶æ„
        config['model'] = trial.suggest_categorical(
            'model', 
            ['resnet18', 'resnet50', 'densenet121', 'efficientnet_b0']
        )
        
        # æ•°æ®å¢å¼ºçº§åˆ«
        config['augment_level'] = trial.suggest_categorical(
            'augment_level', 
            ['light', 'medium', 'aggressive']
        )
        
        # å›¾åƒå°ºå¯¸
        config['img_size'] = trial.suggest_categorical('img_size', [224, 384])
        
        # Weight decay
        config['weight_decay'] = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)
        
        # æŸå¤±å‡½æ•°
        config['loss'] = trial.suggest_categorical('loss', ['weighted_ce', 'focal'])
        
        if config['loss'] == 'focal':
            # Focal loss gamma
            config['focal_gamma'] = trial.suggest_float('focal_gamma', 1.0, 3.0)
        
        # Epochsï¼ˆå¯ä»¥è®¾ç½®è¾ƒå°å€¼åŠ é€Ÿæœç´¢ï¼‰
        config['epochs'] = trial.suggest_int('epochs', 10, 30)
        
        # 2. è®¾ç½®è¾“å‡ºç›®å½•
        trial_dir = self.output_dir / f'trial_{trial.number}'
        config['output_dir'] = str(trial_dir)
        
        # 3. ä¿å­˜é…ç½®
        config_path = trial_dir / 'config.yaml'
        trial_dir.mkdir(parents=True, exist_ok=True)
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f)
        
        # 4. è¿è¡Œè®­ç»ƒ
        print(f"\n{'='*60}")
        print(f"Trial {trial.number}: å¼€å§‹è®­ç»ƒ")
        print(f"{'='*60}")
        print(f"å‚æ•°:")
        for key, value in config.items():
            if key not in ['output_dir', 'data_root']:
                print(f"  {key}: {value}")
        
        cmd = [
            'python', 'src/train.py',
            '--config', str(config_path)
        ]
        
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='ignore'
            )
            
            if result.returncode != 0:
                print(f"[ERROR] è®­ç»ƒå¤±è´¥")
                raise optuna.TrialPruned()
            
            print(f"[SUCCESS] è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            print(f"[ERROR] è¿è¡Œå¤±è´¥: {e}")
            raise optuna.TrialPruned()
        
        # 5. æå–ç»“æœ
        score = self.extract_score(trial_dir)
        
        if score is None:
            raise optuna.TrialPruned()
        
        print(f"\nTrial {trial.number} ç»“æœ: {self.target_metric} = {score:.4f}")
        
        return score
    
    def extract_score(self, trial_dir: Path) -> float:
        """ä»è®­ç»ƒç»“æœä¸­æå–ç›®æ ‡æŒ‡æ ‡"""
        metrics_file = trial_dir / 'metrics_history.csv'
        
        if not metrics_file.exists():
            return None
        
        try:
            df = pd.read_csv(metrics_file)
            
            if self.target_metric in df.columns:
                # è¿”å›æœ€ä½³epochçš„ç›®æ ‡æŒ‡æ ‡
                best_score = df[self.target_metric].max()
                return float(best_score)
            else:
                return None
                
        except Exception as e:
            print(f"[ERROR] è¯»å–ç»“æœå¤±è´¥: {e}")
            return None
    
    def optimize(self, n_trials: int = 20, n_jobs: int = 1, timeout: int = None):
        """
        è¿è¡ŒOptunaä¼˜åŒ–
        
        Args:
            n_trials: è¯•éªŒæ¬¡æ•°
            n_jobs: å¹¶è¡Œä»»åŠ¡æ•°ï¼ˆ>1æ—¶å¯ç”¨å¹¶è¡Œæœç´¢ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        # åˆ›å»ºæˆ–åŠ è½½study
        storage = f'sqlite:///{self.output_dir}/optuna.db' if self.storage_path is None else self.storage_path
        
        study = optuna.create_study(
            study_name=self.study_name,
            storage=storage,
            direction='maximize',  # æœ€å¤§åŒ–ç›®æ ‡æŒ‡æ ‡
            load_if_exists=True,
            sampler=optuna.samplers.TPESampler(seed=42)  # è´å¶æ–¯ä¼˜åŒ–
        )
        
        print(f"\n{'='*60}")
        print(f"å¼€å§‹Optunaè¶…å‚æ•°æœç´¢")
        print(f"{'='*60}")
        print(f"Trialæ•°é‡: {n_trials}")
        print(f"å¹¶è¡Œä»»åŠ¡: {n_jobs}")
        print(f"ç›®æ ‡æŒ‡æ ‡: {self.target_metric} (æœ€å¤§åŒ–)")
        print(f"\n")
        
        # è¿è¡Œä¼˜åŒ–
        study.optimize(
            self.objective,
            n_trials=n_trials,
            n_jobs=n_jobs,
            timeout=timeout,
            show_progress_bar=True
        )
        
        # è¾“å‡ºç»“æœ
        self.print_results(study)
        
        # ä¿å­˜ç»“æœ
        self.save_results(study)
        
        return study
    
    def print_results(self, study: optuna.Study):
        """æ‰“å°ä¼˜åŒ–ç»“æœ"""
        print(f"\n{'='*60}")
        print(f"ä¼˜åŒ–å®Œæˆ!")
        print(f"{'='*60}")
        
        print(f"\næ€»è¯•éªŒæ•°: {len(study.trials)}")
        print(f"  - å®Œæˆ: {len([t for t in study.trials if t.state == TrialState.COMPLETE])}")
        print(f"  - å‰ªæ: {len([t for t in study.trials if t.state == TrialState.PRUNED])}")
        print(f"  - å¤±è´¥: {len([t for t in study.trials if t.state == TrialState.FAIL])}")
        
        if len(study.best_trials) > 0:
            print(f"\nğŸ† æœ€ä½³ç»“æœ:")
            print(f"  Trial {study.best_trial.number}")
            print(f"  {self.target_metric}: {study.best_value:.4f}")
            
            print(f"\næœ€ä½³å‚æ•°:")
            for key, value in study.best_params.items():
                print(f"  {key}: {value}")
            
            # ä¿å­˜æœ€ä½³é…ç½®
            best_config = self.base_config.copy()
            best_config.update(study.best_params)
            
            best_config_path = self.output_dir / 'best_config.yaml'
            with open(best_config_path, 'w', encoding='utf-8') as f:
                yaml.dump(best_config, f)
            
            print(f"\næœ€ä½³é…ç½®å·²ä¿å­˜: {best_config_path}")
            
            # å‚æ•°é‡è¦æ€§åˆ†æ
            if len(study.trials) >= 10:
                print(f"\nğŸ“Š å‚æ•°é‡è¦æ€§åˆ†æ:")
                try:
                    importances = optuna.importance.get_param_importances(study)
                    for param, importance in sorted(importances.items(), 
                                                   key=lambda x: x[1], 
                                                   reverse=True)[:5]:
                        print(f"  {param}: {importance:.3f}")
                except Exception:
                    pass
    
    def save_results(self, study: optuna.Study):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        # ä¿å­˜æ‰€æœ‰è¯•éªŒçš„æ‘˜è¦
        trials_data = []
        for trial in study.trials:
            if trial.state == TrialState.COMPLETE:
                row = {
                    'trial_number': trial.number,
                    'value': trial.value,
                    'state': trial.state.name
                }
                row.update(trial.params)
                trials_data.append(row)
        
        if len(trials_data) > 0:
            df = pd.DataFrame(trials_data)
            summary_path = self.output_dir / 'trials_summary.csv'
            df.to_csv(summary_path, index=False)
            print(f"\n[ä¿å­˜] è¯•éªŒæ‘˜è¦: {summary_path}")
            
            # æ‰“å°Top 5
            print(f"\nTop 5 é…ç½®:")
            top5 = df.nlargest(5, 'value')
            print(top5[['trial_number', 'value', 'lr', 'model', 'augment_level']].to_string(index=False))
        
        # ç”Ÿæˆå¯è§†åŒ–ï¼ˆå¦‚æœå®‰è£…äº†matplotlibï¼‰
        try:
            import matplotlib.pyplot as plt
            
            # ä¼˜åŒ–å†å²
            fig = optuna.visualization.matplotlib.plot_optimization_history(study)
            fig.savefig(self.output_dir / 'optimization_history.png', dpi=200, bbox_inches='tight')
            
            # å‚æ•°é‡è¦æ€§
            if len(study.trials) >= 10:
                fig = optuna.visualization.matplotlib.plot_param_importances(study)
                fig.savefig(self.output_dir / 'param_importances.png', dpi=200, bbox_inches='tight')
            
            # Parallel coordinate plot
            fig = optuna.visualization.matplotlib.plot_parallel_coordinate(study)
            fig.savefig(self.output_dir / 'parallel_coordinate.png', dpi=200, bbox_inches='tight')
            
            print(f"[ä¿å­˜] å¯è§†åŒ–å›¾è¡¨: {self.output_dir}/*.png")
            
        except ImportError:
            print("[INFO] matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        except Exception as e:
            print(f"[WARNING] å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description='Optunaè¶…å‚æ•°æœç´¢')
    parser.add_argument('--config', default='src/configs/baseline_resnet18.yaml',
                       help='åŸºç¡€é…ç½®æ–‡ä»¶')
    parser.add_argument('--n_trials', type=int, default=20,
                       help='è¯•éªŒæ¬¡æ•°')
    parser.add_argument('--n_jobs', type=int, default=1,
                       help='å¹¶è¡Œä»»åŠ¡æ•°')
    parser.add_argument('--target', default='macro_recall',
                       choices=['macro_recall', 'pneumonia_recall', 'val_acc', 'macro_f1'],
                       help='ä¼˜åŒ–ç›®æ ‡æŒ‡æ ‡')
    parser.add_argument('--timeout', type=int, default=None,
                       help='è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--study_name', default=None,
                       help='Studyåç§°ï¼ˆç”¨äºæ¢å¤æˆ–ç»§ç»­ä¼˜åŒ–ï¼‰')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = OptunaTrainer(
        base_config_path=args.config,
        target_metric=args.target,
        study_name=args.study_name
    )
    
    # è¿è¡Œä¼˜åŒ–
    trainer.optimize(
        n_trials=args.n_trials,
        n_jobs=args.n_jobs,
        timeout=args.timeout
    )


if __name__ == '__main__':
    main()

